[{"authors":["**Pilhyeon Lee**","Jinglu Wang","Yan Lu","Hyeran Byun"],"categories":[],"content":"","date":1612234800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612234800,"objectID":"2bebb22a53eb26d29878c55e22d49ff0","permalink":"https://pilhyeon.github.io/publication/2021_aaai_uncertainty-modeling/","publishdate":"2020-12-02T12:00:00+09:00","relpermalink":"/publication/2021_aaai_uncertainty-modeling/","section":"publication","summary":"Weakly-supervised temporal action localization aims to learn detecting temporal intervals of action classes with only video-level labels. To this end, it is crucial to separate frames of action classes from the background frames (i.e., frames not belonging to any action classes). In this paper, we present a new perspective on background frames where they are modeled as out-of-distribution samples regarding their inconsistency. Then, background frames can be detected by estimating the probability of each frame being out-of-distribution, known as uncertainty, but it is infeasible to directly learn uncertainty without frame-level labels. To realize the uncertainty learning in the weakly-supervised setting, we leverage the multiple instance learning formulation. Moreover, we further introduce a background entropy loss to better discriminate background frames by encouraging their in-distribution (action) probabilities to be uniformly distributed over all action classes. Experimental results show that our uncertainty modeling is effective at alleviating the interference of background frames and brings a large performance gain without bells and whistles. We demonstrate that our model significantly outperforms state-of-the-art methods on the benchmarks, THUMOS'14 and ActivityNet (1.2 \u0026 1.3). Our code is available at https://github.com/Pilhyeon/WTAL-Uncertainty-Modeling.","tags":[],"title":"Weakly-supervised Temporal Action Localization by Uncertainty Modeling","type":"publication"},{"authors":["Sunhee Hwang$^*$","Sungho Park$^*$","**Pilhyeon Lee**$^*$","Seogkyu Jeon","Dohyung Kim","Hyeran Byun"],"categories":[],"content":"","date":1606705200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606705200,"objectID":"d1ba2fb223a79f5ba243c3dde4f92356","permalink":"https://pilhyeon.github.io/publication/2020_accv_transferable-fairness/","publishdate":"2020-11-30T12:00:00+09:00","relpermalink":"/publication/2020_accv_transferable-fairness/","section":"publication","summary":"Recent studies have revealed the importance of fairness in machine learning and computer vision systems, in accordance with the concerns about the unintended social discrimination produced by the systems. In this work, we aim to tackle the fairness-aware image classification problem, whose goal is to classify a target attribute (eg, attractiveness) in a fair manner regarding protected attributes (eg, gender, age, race). To this end, existing methods mainly rely on protected attribute labels for training, which are costly and sometimes unavailable for real-world scenarios. To alleviate the restriction and enlarge the scalability of fair models, we introduce a new framework where a fair classification model can be trained on datasets without protected attribute labels (ie, target datasets) by exploiting knowledge from pre-built benchmarks (ie, source datasets). Specifically, when training a target attribute encoder, we encourage its representations to be independent of the features from the pre-trained encoder on a source dataset. Moreover, we design a Group-wise Fair loss to minimize the gap in error rates between different protected attribute groups. To the best of our knowledge, this work is the first attempt to train the fairness-aware image classification model on a target dataset without protected attribute annotations. To verify the effectiveness of our approach, we conduct experiments on CelebA and UTK datasets with two settings: the conventional and the transfer settings. In the both settings, our model shows the fairest results when compared to the existing methods.","tags":[],"title":"Exploiting Transferable Knowledge for Fairness-aware Image Classification","type":"publication"},{"authors":["**Pilhyeon Lee**","Youngjung Uh","Hyeran Byun"],"categories":[],"content":"","date":1581044400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581044400,"objectID":"15bd45477cb63bcf6d826ccf162fd25b","permalink":"https://pilhyeon.github.io/publication/2020_aaai_bas-net/","publishdate":"2020-02-07T12:00:00+09:00","relpermalink":"/publication/2020_aaai_bas-net/","section":"publication","summary":"Weakly-supervised temporal action localization is a very challenging problem because frame-wise labels are not given in the training stage while the only hint is video-level labels: whether each video contains action frames of interest. Previous methods aggregate frame-level class scores to produce video-level prediction and learn from video-level action labels. This formulation does not fully model the problem in that background frames are forced to be misclassified as action classes to predict video-level labels accurately. In this paper, we design Background Suppression Network (BaS-Net) which introduces an auxiliary class for background and has a two-branch weight-sharing architecture with an asymmetrical training strategy. This enables BaS-Net to suppress activations from background frames to improve localization performance. Extensive experiments demonstrate the effectiveness of BaS-Net and its superiority over the state-of-the-art methods on the most popular benchmarks - THUMOS'14 and ActivityNet. Our code and the trained model are available at [https://github.com/Pilhyeon/BaSNet-pytorch](https://github.com/Pilhyeon/BaSNet-pytorch).","tags":[],"title":"Background Suppression Network for Weakly-supervised Temporal Action Localization","type":"publication"},{"authors":null,"categories":null,"content":"\r[13/04/20] New paper on Stochastic Unit Commitment in Low-Inertia Grids published on IEEE Transactions on Power Systems.\n[12/02/20] Seminar presentation on Data-driven decentralised control design in Active Distribution Networks at UCY.\n[31/12/19] New paper on A Robust Coordinated Expansion Planning Model For Wind Farm-Integrated Power Systems With Flexibility Sources Using Affine Policies published on IEEE Systems Journal.\n[2020. 12.] Our paper  on weakly-supervised temporal action localization was accepted to AAAI 2021 .\n","date":1512054000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512054000,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"https://pilhyeon.github.io/news/","publishdate":"2017-12-01T00:00:00+09:00","relpermalink":"/news/","section":"","summary":"\r\nList of news.\r\n","tags":[],"title":"News","type":"page"}]